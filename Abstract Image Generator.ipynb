{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tensorflow.keras import layers,models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\ashmi\\\\Downloads\\\\Compressed\\\\archive_3.zip'\n",
    "\n",
    "extract='abstract_art_512'\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Resize images to 64x64\n",
    "    transforms.ToTensor(),         # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=extract, transform=transform)\n",
    "batch_size= 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6272)              633472    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 64)       131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        9411      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,036,291\n",
      "Trainable params: 1,036,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generator_rex(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7 * 7 * 128, input_dim=latent_dim))\n",
    "    model.add(layers.Reshape((7, 7, 128)))\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(3, (7, 7), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "latent_dim = 100\n",
    "generator = generator_rex(latent_dim)\n",
    "\n",
    "\n",
    "\n",
    "#Gen Arch\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        1792      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376,449\n",
      "Trainable params: 375,681\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def discriminator_rex(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create discriminator model\n",
    "discriminator = discriminator_rex(input_shape)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Disc\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genzloss(fake_output):\n",
    "    return tf.keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Define discriminator loss function\n",
    "def discloss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = tf.reduce_mean(real_loss) + tf.reduce_mean(fake_loss)\n",
    "    return total_loss\n",
    "\n",
    "# Define optimizers\n",
    "grex_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "drex_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Instantiate generator and discriminator\n",
    "latent_dim = 100\n",
    "input_shape = (28,28,3)\n",
    "generator = generator_rex(latent_dim)\n",
    "discriminator = discriminator_rex(input_shape)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = genzloss(fake_output)\n",
    "        disc_loss = discloss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    grex_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    drex_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Train the GAN\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(dataloader):\n",
    "        # Reshape images to correct shape\n",
    "        images = tf.transpose(images, [0, 2, 3, 1])  # Change shape from (batch_size, channels, height, width) to (batch_size, height, width, channels)\n",
    "        train_step(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
